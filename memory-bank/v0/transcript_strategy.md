# TwinCore Transcript Ingestion Strategy

This document outlines the strategy for handling streaming transcript data within the TwinCore prototype, ensuring both semantic searchability of individual utterances and the integrity of the complete transcript record.

## Core Goal

Efficiently ingest real-time transcript snippets (user utterances) while maintaining a link to the complete transcript document generated at the end of a session. Allow for semantic retrieval over individual snippets and provide a mechanism to access the full raw transcript file.

## Data Modeling

1.  **Overall Transcript as a `Document`:**
    *   The entire conversation transcript for a given session is treated as a single logical `Document` entity within the system.
    * Chunks as Snippets: Each user's utterance (dialogue turn) streamed in is a chunk of this logical document.
    *   **Neo4j:** A single `(:Document)` node will represent the entire transcript.
        *   **Properties:**
            *   `document_id`: A unique UUID generated by Dev A at the start of transcription for the session. This ID remains consistent for the entire transcript.
            *   `source_type`: Set to `'transcript'`.
            *   `name`: Descriptive name, e.g., "Transcript for Session [Session Name/ID]".
            *   `session_id`: UUID linking to the relevant `Session` node.
            *   `project_id`: (Optional) UUID linking to the relevant `Project` node.
            *   `timestamp`: Timestamp of the session start or transcript creation.
            *   `source_uri`: (Populated later) URI pointing to the location where the complete raw transcript file is stored by Dev A's system. Initially null.
        *   **Relationships:**
            *   `(Document)-[:ATTACHED_TO]->(Session)`
            *   Potentially `(Document)-[:RELATED_TO]->(Project)`

2.  **Individual Utterances as Chunks/Snippets:**
    *   Each streamed chunk, typically representing a single user's turn or utterance, is treated as a distinct piece of text content associated with the parent transcript `Document`.
    *   **Qdrant:** Each utterance is stored as a point in the `twin_memory` collection.
        *   **Vector:** Embedding of the `text_content`.
        *   **Payload:**
            *   `chunk_id`: Unique UUID for this specific utterance/snippet.
            *   `text_content`: The actual text of the utterance.
            *   `source_type`: Set to `'transcript_snippet'`.
            *   `timestamp`: Accurate ISO 8601 timestamp when the utterance occurred.
            *   `user_id`: UUID of the user who spoke the utterance.
            *   `session_id`: UUID of the session (links to Neo4j `Session`).
            *   `project_id`: (Optional) UUID of the project (links to Neo4j `Project`).
            *   `doc_id`: **Crucially**, this MUST be the consistent `document_id` of the parent transcript `Document` node created in Neo4j for this session. Dev A must provide this with every chunk.
            *   `message_id`: (Optional) A unique identifier for this specific utterance chunk provided by Dev A's system.
            *   `is_twin_interaction`: `false`.
            *   `is_private`: `false` (typically, transcripts are shared within the session context).
    *   **Neo4j:** Individual utterances **do not** typically get their own dedicated nodes (like `:Message` or `:Chunk`) to avoid graph database bloat. We rely on Qdrant for snippet storage and the parent `Document` node in Neo4j as the anchor. Relationships like `(User)-[:SPOKE_SNIPPET {timestamp: ...}]->(Document)` could be considered if needed, but are likely redundant given Qdrant payload data.
        * Create a single` (:Document {document_id: 'transcript_session_xyz_id', source_type: 'transcript', name: 'Session XYZ Transcript'})` node representing the entire transcript.
        * Link this node to the Session node: `(doc)-[:ATTACHED_TO]->(session)`.
        * Link participating User nodes to the Session: `(user)-[:PARTICIPATED_IN]->(session)`

## Ingestion Process

1.  **Session Start (Responsibility: Dev A):**
    *   Generate a unique `document_id` (UUID) for the transcript of the upcoming session.
    *   Initiate the Neo4j `Document` node creation via an initial API call or ensure it's created upon receiving the first chunk.

2.  **Streaming Ingestion (Responsibility: Dev A -> Dev B):**
    *   As Dev A's system receives transcript utterances:
        *   It calls the dedicated TwinCore endpoint: `POST /v1/ingest/chunk`.
        *   **API Endpoint:** `POST /v1/ingest/chunk`
            *   **Description:** Ingests a single chunk of text, typically a transcript snippet, associated with a parent document. Handles embedding and storage.
            *   **Request Body:**
                ```json
                {
                  "user_id": "string (uuid)", // REQUIRED: Speaker of the utterance
                  "session_id": "string (uuid)", // REQUIRED: Session context
                  "doc_id": "string (uuid)", // REQUIRED: The consistent ID of the parent transcript Document
                  "project_id": "string (uuid), optional", // Optional project context
                  "chunk_id": "string (uuid), optional", // Optional: ID for this specific chunk from source
                  "text": "string", // REQUIRED: The utterance text content
                  "timestamp": "string (isoformat)", // REQUIRED: Time the utterance occurred
                  "metadata": "object, optional" // Optional: Any additional source-specific metadata
                }
                ```
            *   **TwinCore Action (Dev B):**
                *   Validates the request.
                *   Ensures the parent `Document` node exists in Neo4j (creating it if this is the first chunk for that `doc_id`, using `session_id`, `project_id`, `user_id` for context).
                *   Calls `EmbeddingService` to get the vector for `text`.
                *   Upserts the point into Qdrant with `source_type: 'transcript_snippet'` and all provided metadata mapped to the payload schema.
                *   Updates relevant Neo4j relationships if necessary (e.g., ensuring `(User)-[:PARTICIPATED_IN]->(Session)` exists).
            *   **Response:** `202 Accepted`.

3.  **Session End & Raw File Storage (Responsibility: Dev A):**
    *   Dev A's system accumulates the raw transcript data throughout the session.
    *   At session end, Dev A constructs the complete raw transcript file (e.g., `.txt`, `.json` with timing).
    *   Dev A stores this raw file in their own backend storage (e.g., S3, Supabase Storage).
    *   Dev A obtains the persistent URI for the stored raw file.

4.  **Linking Raw File URI (Responsibility: Dev A -> Dev B):**
    *   Dev A calls the dedicated metadata update endpoint `POST /v1/documents/{doc_id}/metadata`, providing the `doc_id` of the transcript and the `source_uri`.
    *   **API Call:** `POST /v1/documents/{doc_id}/metadata` (replace `{doc_id}` with the actual ID)
    *   **Request Body:**
        ```json
        {
          "user_id": "string (uuid)", // User performing the update action (e.g., system user)
          "source_uri": "string", // REQUIRED: The URI of the raw transcript file stored by Dev A
          "timestamp": "string (isoformat)", // Optional: Timestamp of session end / transcript completion (defaults to now if omitted)
          "metadata": { // Optional: Final metadata like total duration, final participant list etc.
            "duration_seconds": 1850,
            "final_participant_ids": ["uuid1", "uuid2", "uuid3"]
           }
        }
        ```
    *   **TwinCore Action (Dev B):**
        *   Validates the request body and path parameter `doc_id`.
        *   Locates the corresponding `(:Document {document_id: $doc_id})` node in Neo4j.
        *   Updates the node's properties, setting `source_uri` and merging any additional metadata provided.
    *   **Response:** `200 OK`.

## Retrieval

*   **Semantic Search over Utterances:** Standard retrieval endpoints (`/v1/retrieve/context`, `/v1/retrieve/group`, etc.) can find relevant transcript snippets by filtering Qdrant searches using `session_id`, `project_id`, `user_id`, and ensuring `source_type == 'transcript_snippet'` if needed. The `doc_id` allows grouping snippets from the same transcript.
*   **Accessing Full Raw Transcript:**
    *   A potential new endpoint like `GET /v1/documents/{doc_id}/metadata` could be added.
    *   This endpoint would query Neo4j for the `Document` node with the given `doc_id`.
    *   It would return metadata including the `source_uri`.
    *   The calling service (Dev A) would then use this `source_uri` to fetch the raw file directly from its storage location.

## Summary of Required Changes

1.  **`dataSchema.md`:**
    *   Add `source_uri: string | null` property to the Neo4j `Document` node definition.
    *   Emphasize the use of `source_type: 'transcript_snippet'` in Qdrant payloads for utterances.
    *   Clarify the importance of the consistent `doc_id` field linking Qdrant snippets to the Neo4j `Document` node.
2.  **`api.md`:**
    *   Define the new endpoint `POST /v1/ingest/chunk` with its request body and purpose.
    *   Update the description of `POST /v1/ingest/document` to explicitly mention its use for metadata-only updates (like adding `source_uri`) by omitting the `text` field.
    *   (Optional) Define `GET /v1/documents/{doc_id}/metadata` if direct access to the raw file URI via TwinCore API is desired.
3.  **`systemPatterns.md`:** No fundamental architectural changes needed. Logic fits within existing layers.

This strategy provides a robust way to handle streaming transcripts, leveraging Qdrant for semantic search on snippets and Neo4j for structural representation and linking to the raw data managed by Dev A. 